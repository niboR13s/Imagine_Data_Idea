{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c42a22",
   "metadata": {},
   "source": [
    "# Import lib's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2539a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os as os\n",
    "import subprocess\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115c401",
   "metadata": {},
   "source": [
    "# Location's\n",
    "\n",
    "Below are the file path definitions required for the Script. These variables tell the script where to find the software, the 3D environment, the logic, and the settings.\n",
    "\n",
    "\n",
    "`BLENDER_EXE`: The absolute file path to the Blender application executable (.exe) on your computer.\n",
    "\n",
    "`BLEND_FILE`: The path to the .blend project file that acts as the base template for the simulation.\n",
    "\n",
    "`EXCEL_FILE`: The path to the Excel workbook\n",
    "\n",
    "`SENSOR_PROGRAM_FILE`: The path to the external Python script containing the Blender-specific logic\n",
    "\n",
    "`DATA_SAVE_LOCATION`: The location where the generated data is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f206fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project dir: c:\\Users\\RobinSchool\\Stichting Hogeschool Utrecht\\MNLE Imagine Project - Documents\\DataProgram\\Program's\n",
      "Blender file location: c:\\Users\\RobinSchool\\Stichting Hogeschool Utrecht\\MNLE Imagine Project - Documents\\DataProgram\\Program's\\..\\Blender_Generated_Data\\DataGenerator.blend\n"
     ]
    }
   ],
   "source": [
    "# User specific\n",
    "BLENDER_EXE = r\"C:\\Program Files\\Blender Foundation\\Blender 5.0\\blender.exe\"\n",
    "\n",
    "PROJECT_DIR             = os.getcwd()\n",
    "\n",
    "# Project specific\n",
    "BLEND_FILE              = os.path.join(PROJECT_DIR, r\"..\\Blender_Generated_Data\\DataGenerator.blend\")\n",
    "EXCEL_FILE              = os.path.join(PROJECT_DIR, r\"Data_generation_settings.xlsx\")\n",
    "SENSOR_PROGRAM_FILE     = os.path.join(PROJECT_DIR, r\"BlenderSensorProgram.py\")\n",
    "\n",
    "OUTPUT_ROOT             = os.path.join(PROJECT_DIR, r\"..\\Blender_Generated_Data\")\n",
    "\n",
    "print(f\"Project dir: {PROJECT_DIR}\")\n",
    "print(f\"Blender file location: {BLEND_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b4b467",
   "metadata": {},
   "source": [
    "# Vallidating the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81ffcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_files = {\n",
    "    \"Blender Application\": BLENDER_EXE,\n",
    "    \"Excel Configuration\": EXCEL_FILE,\n",
    "    \"Blender Scene File\": BLEND_FILE,\n",
    "    \"Blender Python Script\": SENSOR_PROGRAM_FILE\n",
    "}\n",
    "\n",
    "errors =0\n",
    "\n",
    "    \n",
    "# 1. Check Critical Files\n",
    "for name, path in critical_files.items():\n",
    "    if not os.path.exists(path):\n",
    "        # Only print if NOT found\n",
    "        print(f\"❌ MISSING FILE: {name}\")\n",
    "        print(f\"   -> Searched at: {path}\")\n",
    "        errors+=1\n",
    "\n",
    "if errors:\n",
    "    raise Exception(f\"{errors} wrong file paths\")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(OUTPUT_ROOT):\n",
    "        os.makedirs(OUTPUT_ROOT)\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: Could not create Output directory: {OUTPUT_ROOT}\")\n",
    "    print(f\"   -> Details: {e}\")\n",
    "    all_good = False\n",
    "\n",
    "\n",
    "if errors:\n",
    "    raise Exception(\"Output couln't be created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d0688",
   "metadata": {},
   "source": [
    "# Exel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e3be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(df):\n",
    "    df.columns = df.columns.str.replace(r'\\s*\\(.*\\)', '', regex=True)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "def load_excel_data():\n",
    "    if not os.path.exists(EXCEL_FILE):\n",
    "        print(f\"File not found: {EXCEL_FILE}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"--- Loading {EXCEL_FILE} ---\")\n",
    "\n",
    "    # ==========================================\n",
    "    # STEP 1: Load Definitions (Tables)\n",
    "    # ==========================================\n",
    "    try:\n",
    "        # Load Sensors (Sheet 'Sensors', index 'sensor_id')\n",
    "        df_sensors = pd.read_excel(EXCEL_FILE, sheet_name='Sensors')\n",
    "        df_sensors = clean_cols(df_sensors)\n",
    "        df_sensors.set_index('sensor_id', inplace=True)\n",
    "        \n",
    "        # Load Positions (Sheet 'Pos', index 'config_id')\n",
    "        df_positions = pd.read_excel(EXCEL_FILE, sheet_name='Pos')\n",
    "        df_positions = clean_cols(df_positions)\n",
    "        df_positions.set_index('config_id', inplace=True)\n",
    "        \n",
    "        # Load Datasets (Sheet 'Data', index 'dataset_name')\n",
    "        df_datasets = pd.read_excel(EXCEL_FILE, sheet_name='Data')\n",
    "        df_datasets.set_index('dataset_name', inplace=True)\n",
    "        \n",
    "        print(\"Definitions loaded:\")\n",
    "        print(f\"   - {len(df_sensors)} Sensors\")\n",
    "        print(f\"   - {len(df_positions)} Positions\")\n",
    "        print(f\"   - {len(df_datasets)} Datasets\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading definitions: {e}\")\n",
    "        return\n",
    "\n",
    "    # ==========================================\n",
    "    # STEP 2: Load the Matrix\n",
    "    # ==========================================\n",
    "    try:\n",
    "        df_matrix = pd.read_excel(EXCEL_FILE, sheet_name='Run_Matrix')\n",
    "        \n",
    "        # Cleanup: Drop rows where 'Batch_ID' is empty\n",
    "        df_matrix = df_matrix.dropna(subset=['Batch_ID'])\n",
    "        \n",
    "        # 1. FIX: Filter on the 'Generate' column, not Batch_ID\n",
    "        # We assume the column is named 'Generate' as shown in the image\n",
    "        # active_batches = df_matrix[df_matrix['Generate'].astype(str).str.upper().isin(['JA', 'YES', 'TRUE'])]\n",
    "        \n",
    "        # print(f\"Matrix loaded: {len(active_batches)} active batches found.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading Matrix: {e}\")\n",
    "        return None ,None ,None , None\n",
    "  \n",
    "    return df_sensors, df_datasets, df_positions,df_matrix\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc7c68",
   "metadata": {},
   "source": [
    "# launc blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87db0128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blender(sensor_spec,pos_spec,data_spec,output_dir):\n",
    "    cmd = [\n",
    "        BLENDER_EXE,\n",
    "        \"-b\", BLEND_FILE,            # Run in background (no UI)\n",
    "        \"-P\", SENSOR_PROGRAM_FILE,   # Run the python script\n",
    "        \"--\",                        # Separator (args after this are for our script)\n",
    "        \n",
    "        # Pass arguments (convert numbers to strings!)\n",
    "        \"--sensor_res\", f\"{int(sensor_spec['resolution_width'])}x{int(sensor_spec['resolution_height'])}\",\n",
    "        \"--sensor_fov\", f\"{sensor_spec['fov_horizontal']}x{sensor_spec['fov_vertical']}\",\n",
    "        \"--position\", f\"{pos_spec['pos_x']},{pos_spec['pos_y']},{pos_spec['pos_z']}\",\n",
    "        \"--samples\", str(int(data_spec['num_samples'])),\n",
    "        \"--output\", output_dir,\n",
    "        \n",
    "        # Optional args (using .get() in case they are missing in Excel)\n",
    "        \"--noise\", str(sensor_spec.get('noise_level', 0.0)),\n",
    "        \"--target_name\", \"Cube\"\n",
    "    ]\n",
    "\n",
    "    # Add ranges if they exist in the dataset spec\n",
    "    if 'rot_range' in data_spec:\n",
    "        cmd.extend([\"--rot_range\", str(data_spec['rot_range'])])\n",
    "    if 'trans_range' in data_spec:\n",
    "        cmd.extend([\"--trans_range\", str(data_spec['trans_range'])])\n",
    "\n",
    "    # 4. Execute\n",
    "    # print(f\"      >>> Launching Blender for batch: ...\")\n",
    "    try:\n",
    "        # check=True will raise an error if Blender crashes\n",
    "        subprocess.run(cmd, check=True) \n",
    "        # print(\"      >>> Done.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"      !!! Blender Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a393759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading c:\\Users\\RobinSchool\\Stichting Hogeschool Utrecht\\MNLE Imagine Project - Documents\\DataProgram\\Program's\\Data_generation_settings.xlsx ---\n",
      "Definitions loaded:\n",
      "   - 5 Sensors\n",
      "   - 3 Positions\n",
      "   - 4 Datasets\n",
      "Matrix loaded: 2 active batches found.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Batch Status Overview\n",
       "- Test_1: Completed successfully (1 runs)\n",
       "- Test_2: Completed successfully (1 runs)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "--- **All Batches Finished** ---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No errors occurred during generation.\n"
     ]
    }
   ],
   "source": [
    "ERROR_REPORT_MODE = 'SUMMARY' \n",
    "\n",
    "# 1. Load Data\n",
    "df_sensors, df_datasets, df_positions, df_matrix = load_excel_data()\n",
    "\n",
    "# 2. Filter active batches\n",
    "active_batches = df_matrix[df_matrix['Generate'].astype(str).str.upper().isin(['JA', 'YES', 'TRUE'])]\n",
    "print(f\"Matrix loaded: {len(active_batches)} active batches found.\")\n",
    "\n",
    "# Get column names\n",
    "matrix_cols = df_matrix.columns.tolist()\n",
    "\n",
    "# --- STATUS TRACKING ---\n",
    "batch_statuses = {}  # Display text\n",
    "batch_errors = {}    # Store exceptions: { 'Batch_ID': [list of errors] }\n",
    "\n",
    "# Pre-fill dictionary\n",
    "for idx, row in active_batches.iterrows():\n",
    "    b_id = row['Batch_ID']\n",
    "    batch_statuses[b_id] = \"Waiting...\"\n",
    "    batch_errors[b_id] = []\n",
    "\n",
    "# Function to refresh the screen\n",
    "def update_status_display(handle, statuses):\n",
    "    lines = [\"### Batch Status Overview\"]\n",
    "    for b_id, status in statuses.items():\n",
    "        # Bold text if running or if finished with errors\n",
    "        if \"Running\" in status:\n",
    "            lines.append(f\"- **{b_id}**: {status}\")\n",
    "        elif \"errors\" in status.lower():\n",
    "            lines.append(f\"- **{b_id}** (ATTENTION): {status}\")\n",
    "        else:\n",
    "            lines.append(f\"- {b_id}: {status}\")\n",
    "    \n",
    "    handle.update(Markdown(\"\\n\".join(lines)))\n",
    "\n",
    "# Create display\n",
    "status_handle = display(Markdown(\"Initializing...\"), display_id=True)\n",
    "update_status_display(status_handle, batch_statuses)\n",
    "\n",
    "# --- START PROCESSING ---\n",
    "\n",
    "for idx, row in active_batches.iterrows():\n",
    "    batch_id = row['Batch_ID']\n",
    "    dataset_id = row['Data generation settings']\n",
    "\n",
    "    # Initialize counters for this batch\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    \n",
    "    # Validation\n",
    "    if dataset_id not in df_datasets.index:\n",
    "        batch_statuses[batch_id] = f\"ERROR: Dataset '{dataset_id}' not found!\"\n",
    "        update_status_display(status_handle, batch_statuses)\n",
    "        continue\n",
    "\n",
    "    # Select Sensors & Positions\n",
    "    selected_sensors = []\n",
    "    selected_positions = []\n",
    "\n",
    "    for col_name in matrix_cols:\n",
    "        if col_name in ['Batch_ID', 'Generate', 'Data generation settings']:\n",
    "            continue\n",
    "        \n",
    "        cell_value = row[col_name]\n",
    "        if pd.notna(cell_value) and str(cell_value).strip() != \"\":\n",
    "            if col_name in df_sensors.index:\n",
    "                selected_sensors.append(col_name)\n",
    "            elif col_name in df_positions.index:\n",
    "                selected_positions.append(col_name)\n",
    "\n",
    "    if not selected_sensors or not selected_positions:\n",
    "        batch_statuses[batch_id] = \"Skipped (No sensors/positions selected)\"\n",
    "        update_status_display(status_handle, batch_statuses)\n",
    "        continue\n",
    "\n",
    "    # --- START LOOPS ---\n",
    "    total_steps = len(selected_sensors) * len(selected_positions)\n",
    "    current_step = 0\n",
    "    \n",
    "    for sens_id in selected_sensors:\n",
    "        sensor_spec = df_sensors.loc[sens_id]\n",
    "        \n",
    "        for pos_id in selected_positions:\n",
    "            pos_spec = df_positions.loc[pos_id]\n",
    "            data_spec = df_datasets.loc[dataset_id]\n",
    "            \n",
    "            current_step += 1\n",
    "            \n",
    "            # Construct Status Message\n",
    "            # Shows: Running [1/10] | Success: 0 | Failed: 0\n",
    "            status_msg = (f\"Running [{current_step}/{total_steps}] | \"\n",
    "                          f\"Success: {success_count} | Failed: {fail_count} | \"\n",
    "                          f\"Current: {sens_id} @ {pos_id}\")\n",
    "            \n",
    "            batch_statuses[batch_id] = status_msg\n",
    "            update_status_display(status_handle, batch_statuses)\n",
    "\n",
    "            dir_name = os.path.join(OUTPUT_ROOT, batch_id, sens_id, pos_id)\n",
    "            \n",
    "            # === BLENDER CALL ===\n",
    "            try:\n",
    "                run_blender(sensor_spec, pos_spec, data_spec, dir_name)\n",
    "                success_count += 1\n",
    "            except Exception as e:\n",
    "                fail_count += 1\n",
    "                error_msg = f\"{sens_id}@{pos_id}: {str(e)}\"\n",
    "                batch_errors[batch_id].append(error_msg)\n",
    "\n",
    "    # --- FINALIZE BATCH STATUS ---\n",
    "    if fail_count > 0:\n",
    "        batch_statuses[batch_id] = f\"Finished with {fail_count} errors (Success: {success_count})\"\n",
    "    else:\n",
    "        batch_statuses[batch_id] = f\"Completed successfully ({success_count} runs)\"\n",
    "    \n",
    "    update_status_display(status_handle, batch_statuses)\n",
    "\n",
    "# --- FINAL ERROR REPORT ---\n",
    "display(Markdown(\"--- **All Batches Finished** ---\"))\n",
    "\n",
    "total_errors = sum(len(errs) for errs in batch_errors.values())\n",
    "\n",
    "if total_errors > 0:\n",
    "    print(f\"\\n=== ERROR REPORT (Mode: {ERROR_REPORT_MODE}) ===\")\n",
    "    \n",
    "    for b_id, errors in batch_errors.items():\n",
    "        if not errors:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nBatch: {b_id} ({len(errors)} failures)\")\n",
    "        \n",
    "        if ERROR_REPORT_MODE == 'SUMMARY':\n",
    "            # Only print unique errors to avoid spamming the same message 100 times\n",
    "            # We filter duplicates by converting the list to a set\n",
    "            unique_errors = list(set(errors))\n",
    "            for i, err in enumerate(unique_errors, 1):\n",
    "                print(f\"  {i}. {err}\")\n",
    "            if len(errors) > len(unique_errors):\n",
    "                print(f\"  ... (and {len(errors) - len(unique_errors)} duplicates)\")\n",
    "                \n",
    "        else:\n",
    "            # Print ALL errors\n",
    "            for i, err in enumerate(errors, 1):\n",
    "                print(f\"  {i}. {err}\")\n",
    "else:\n",
    "    print(\"\\nNo errors occurred during generation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
